{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcb1Ra1weqWV"
      },
      "source": [
        "## **Исходные данные:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idEbDhe6fC-c"
      },
      "source": [
        "Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).<br>\n",
        "\n",
        "Данные представлены в формате CSV (Kaggle: Predicting a Biological Response (Прогнозирование биологического ответа)).  Каждая строка представляет молекулу.<br>\n",
        "\n",
        "Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1];\n",
        "Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.<br>\n",
        "\n",
        "\n",
        "Предварительная обработка не требуется, данные уже закодированы и нормализованы.<br>\n",
        "\n",
        "В качестве метрики будем использовать **F1-score**.<br>\n",
        "\n",
        "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvVlDYPSglqp"
      },
      "source": [
        "## **Решение:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--so7k9Y_Dmy",
        "outputId": "a7e18a55-b095-45e4-c1c1-97f7e128f323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "# Подключаем библиотеки\n",
        "from google.colab import drive\n",
        "import numpy as np # для матричных вычислений\n",
        "import pandas as pd # для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt # для визуализации\n",
        "import seaborn as sns # для визуализации\n",
        "\n",
        "from sklearn import linear_model # линейные моделиё\n",
        "from sklearn import tree # деревья решений\n",
        "from sklearn import ensemble # ансамбли\n",
        "from sklearn import metrics # метрики\n",
        "from sklearn import preprocessing # предобработка\n",
        "from sklearn.model_selection import train_test_split # сплитование выборки\n",
        "\n",
        "# Импорт библиотек для оптимизации гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6697loLtOlPX"
      },
      "source": [
        "#### **1. Загрузка и обработка данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cll_sJvOCdX6",
        "outputId": "bee9e635-ea32-4fdf-f1a9-9c6efa13e3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Монтируем Google Диск\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "bc39e68e-ed02-4ee2-9235-7258a2f867a8",
        "outputId": "83b5fc02-b0b6-45fd-d751-e3deda1ee88a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
              "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
              "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
              "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
              "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
              "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
              "\n",
              "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
              "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
              "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
              "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
              "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
              "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
              "\n",
              "   D1774  D1775  D1776  \n",
              "0      0      0      0  \n",
              "1      0      1      0  \n",
              "2      0      0      0  \n",
              "3      0      0      0  \n",
              "4      0      0      0  \n",
              "\n",
              "[5 rows x 1777 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e121d7a-9406-4c7e-ba43-d0b46c81eaad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497009</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132956</td>\n",
              "      <td>0.678031</td>\n",
              "      <td>0.273166</td>\n",
              "      <td>0.585445</td>\n",
              "      <td>0.743663</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.606291</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.803455</td>\n",
              "      <td>0.106105</td>\n",
              "      <td>0.411754</td>\n",
              "      <td>0.836582</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.480124</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209791</td>\n",
              "      <td>0.610350</td>\n",
              "      <td>0.356453</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.679051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538825</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.196344</td>\n",
              "      <td>0.724230</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>0.288764</td>\n",
              "      <td>0.805110</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.781422</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.303809</td>\n",
              "      <td>0.812646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1777 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e121d7a-9406-4c7e-ba43-d0b46c81eaad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e121d7a-9406-4c7e-ba43-d0b46c81eaad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e121d7a-9406-4c7e-ba43-d0b46c81eaad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3529cf49-9562-47bc-82a0-f35c94f13569\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3529cf49-9562-47bc-82a0-f35c94f13569')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3529cf49-9562-47bc-82a0-f35c94f13569 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Загружаем данные\n",
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Andrew_learning/_train_sem09 (1).csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuvSDhgMhKWj",
        "outputId": "27c1466b-baba-45b8-a092-9a10ee0d359e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3751, 1777)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Размерность датафрейма\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-kBuvuPiIUA"
      },
      "source": [
        "**Проверим датафрейм на наличие пропусков и дубликатов, а также на корректность типов данных столбцов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGpn2TydeOW",
        "outputId": "7e575f3f-313e-44c0-a973-59727d9f2570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3751 entries, 0 to 3750\n",
            "Columns: 1777 entries, Activity to D1776\n",
            "dtypes: float64(942), int64(835)\n",
            "memory usage: 50.9 MB\n"
          ]
        }
      ],
      "source": [
        "# Выводим основную информацию о датафрейме\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "K4-d7lcwiilW",
        "outputId": "29521665-7589-4344-d8e9-4dabe7d3fd9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Activity    0\n",
              "D1          0\n",
              "D2          0\n",
              "D3          0\n",
              "D4          0\n",
              "           ..\n",
              "D1772       0\n",
              "D1773       0\n",
              "D1774       0\n",
              "D1775       0\n",
              "D1776       0\n",
              "Length: 1777, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Activity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1772</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1773</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1774</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1775</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D1776</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1777 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Выполним проверку на наличие пропущенных значений NaN в датафрейме\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDlrFsZ7kr2K"
      },
      "source": [
        "Для обработки пропусков воспользуемся **методом fillna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlsArjhHkC3z",
        "outputId": "1bf83392-6e36-4f11-e3cc-ff1ea7264055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество найденных дубликатов: 0\n"
          ]
        }
      ],
      "source": [
        "# Проверка на наличие дубликатов\n",
        "dupl_columns = list(df.columns) # создаем список столбцов dupl_columns, по которым будем искать совпадения\n",
        "# Создаем маску дубликатов с помощью метода duplicated() и произведём фильтрацию\n",
        "mask = df.duplicated(subset=dupl_columns)\n",
        "df_duplicates = df[mask]\n",
        "print(f'Количество найденных дубликатов: {df_duplicates.shape[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmWk057mGO9H",
        "outputId": "986f8867-e9d6-4c8b-92a2-639bd47a6b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Строки, которые являются полными дубликатами:\n",
            "Empty DataFrame\n",
            "Columns: [Activity, D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, D11, D12, D13, D14, D15, D16, D17, D18, D19, D20, D21, D22, D23, D24, D25, D26, D27, D28, D29, D30, D31, D32, D33, D34, D35, D36, D37, D38, D39, D40, D41, D42, D43, D44, D45, D46, D47, D48, D49, D50, D51, D52, D53, D54, D55, D56, D57, D58, D59, D60, D61, D62, D63, D64, D65, D66, D67, D68, D69, D70, D71, D72, D73, D74, D75, D76, D77, D78, D79, D80, D81, D82, D83, D84, D85, D86, D87, D88, D89, D90, D91, D92, D93, D94, D95, D96, D97, D98, D99, ...]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 1777 columns]\n"
          ]
        }
      ],
      "source": [
        "# Выведим строки, которые являются полными дубликатами, т.е совпадают по всем столбцам\n",
        "duplicates = df[df.duplicated()]\n",
        "print(\"Строки, которые являются полными дубликатами:\")\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9g8tgeoJkPI"
      },
      "source": [
        "**Выводы:** Как видно из проведенного анализа в датафрейме отсутствуют пропущенные значения и дубликаты, ввиду того, что согласно исходным данным предварительная обработка датафрейма не требуется, так как данные уже закодированы и нормализованы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKAA7b7ODy1r"
      },
      "source": [
        "#### **2. Разделение данных на тренировочные и тестовые**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgE27kNJHZyC",
        "outputId": "958369e4-155b-43d7-a7d9-fbd50ae7269f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train_shape': (3000, 1776),\n",
              " 'X_test_shape': (751, 1776),\n",
              " 'y_train_distribution': Activity\n",
              " 1    1627\n",
              " 0    1373\n",
              " Name: count, dtype: int64,\n",
              " 'y_test_distribution': Activity\n",
              " 1    407\n",
              " 0    344\n",
              " Name: count, dtype: int64}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Разделение данных на признаки (X) и целевую переменную (y)\n",
        "X = df.drop(columns='Activity')\n",
        "y = df['Activity']\n",
        "\n",
        "# Разделение на тренировочную и тестовую выборки (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Размеры полученных выборок\n",
        "split_info = {\n",
        "    \"X_train_shape\": X_train.shape,\n",
        "    \"X_test_shape\": X_test.shape,\n",
        "    \"y_train_distribution\": y_train.value_counts(),\n",
        "    \"y_test_distribution\": y_test.value_counts(),\n",
        "}\n",
        "split_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JMCRN4mHq9U"
      },
      "source": [
        "Тренировочная выборка: 3000 наблюдений (1627 - класса 1, 1373 - класса 0).<br>\n",
        "Тестовая выборка: 751 наблюдений (407 - класса 1, 344 - класса 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "v5Aec2RnUi--",
        "outputId": "d110b0e9-07a1-4d3b-a646-00a8f0325558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Activity\n",
              "1    0.542255\n",
              "0    0.457745\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.542255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.457745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Проверим, насколько равномерно разделены целевые данные\n",
        "y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1OZvYKzVRLC"
      },
      "source": [
        "Данные разделены примерно одинаково, поэтому делать стратификацию не обязательно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720KkEomEKrd"
      },
      "source": [
        "#### **3. Обучение моделей (логистическая регрессия и случайный лес)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbN4q40Lirwt"
      },
      "source": [
        "Рассчитаем F1-score, построив базовую модель машинного обучения с использованием логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-XtC3oHvlaG",
        "outputId": "68ed9bab-b2f8-46bb-a743-0b8149263fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "logReg_base = linear_model.LogisticRegression(random_state=42, max_iter= 50)\n",
        "\n",
        "logReg_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logReg_base = logReg_base.predict(X_test)\n",
        "\n",
        "f1_logReg_base = metrics.f1_score(y_test, y_pred_logReg_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa8vygUIvlaG",
        "outputId": "678f4fba-38a4-4228-b6e4-d00d6e6c8c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score для базовой модели с использованием логистической регресии равен 0.78\n"
          ]
        }
      ],
      "source": [
        "print('F1-score для базовой модели с использованием логистической регресии равен {:.2f}'.format(f1_logReg_base))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiY4DbDYkTTc"
      },
      "source": [
        "Рассчитаем F1-score, построив базовую модель машинного обучения с использованием алгоритма случайного леса (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eN7fWKirvlaH"
      },
      "outputs": [],
      "source": [
        "rf_base = ensemble.RandomForestClassifier(random_state= 42)\n",
        "\n",
        "rf_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf_base = rf_base.predict(X_test)\n",
        "\n",
        "f1_rf_base = metrics.f1_score(y_test, y_pred_rf_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-fFigyYvlaH",
        "outputId": "ce568f58-7cb6-4972-805d-6ef201f94a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score для базовой модели с использованием алгоритма случайного леса равен 0.81\n"
          ]
        }
      ],
      "source": [
        "print('F1-score для базовой модели с использованием алгоритма случайного леса равен {:.2f}'.format(f1_rf_base))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81CuKLQUmHZq"
      },
      "source": [
        "**Вывод:**<br>\n",
        "В результате выполненных расчетов:<br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.78.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.81.<br>\n",
        "Как видно, случайный лес показал немного лучшие результаты.<br>\n",
        "Далее выполним подбор гиперпараметров для обеих моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwPYqhGMEK1f"
      },
      "source": [
        "#### **4. Подбор гиперпараметров c использованием методов: GridSearchCV, RandomizedSearchCV, Hyperopt, Optuna**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDjl3UkkwM2Z"
      },
      "source": [
        "##### **Построение модели с помощью GridSearchCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk2kwKxx4hl1"
      },
      "source": [
        "\n",
        "*на основе логистической регресии:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LAbI47ZvlaI",
        "outputId": "f7e71135-7e6f-43a1-c3a8-bb271ac5392a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "105 fits failed out of a total of 350.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "105 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.78764576 0.7881061  0.78785511        nan        nan        nan\n",
            " 0.78595876 0.78554044 0.78575044        nan        nan        nan\n",
            " 0.7784629  0.78130206 0.77847737        nan        nan        nan\n",
            " 0.78057242 0.77718464 0.77944268        nan        nan        nan\n",
            " 0.77748086 0.77582871 0.77930517        nan        nan        nan\n",
            " 0.77574954 0.77177561 0.77977812        nan        nan        nan\n",
            " 0.77458483 0.7720333  0.78015342        nan        nan        nan\n",
            " 0.75772746 0.75772746 0.78554509 0.78676988 0.78429729 0.7853432\n",
            " 0.78494013 0.78591072 0.78875614 0.79119008 0.77738224 0.78074228\n",
            " 0.78799749 0.78616604 0.7810739  0.77942326 0.78534717 0.78373643\n",
            " 0.77755074 0.77916669 0.78170813 0.78155377 0.77430303 0.77964432\n",
            " 0.78068116 0.78033229 0.77378594 0.77940228]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 11.8 s, sys: 907 ms, total: 12.7 s\n",
            "Wall time: 8min 35s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "param_grid = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C' : [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
        "\n",
        "    # так как разные алгоритмы поддерживают разные типы регуляризации, то создадим еще 1 набор параметров\n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
        "]\n",
        "\n",
        "gs_logReg = GridSearchCV(\n",
        "    estimator = linear_model.LogisticRegression(random_state= 42, max_iter = 50),\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time gs_logReg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gs_logReg = gs_logReg.predict(X_test)\n",
        "\n",
        "f1_gs_logReg = metrics.f1_score(y_test, y_pred_gs_logReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdCKftWA_ZOa",
        "outputId": "f2914a26-520f-4c77-a431-6188d0c253e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l1', 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18AeeChJ_iNd",
        "outputId": "00a01179-9250-4efe-8984-3ae9583bb3b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на GridSearchCV для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на GridSearchCV для логистической регресии равен {:.2f}'.format(f1_gs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTS1nOvO_9ob"
      },
      "source": [
        "*на основе случайного леса:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuuGYdqJ_qDF",
        "outputId": "7cd0e5a2-fb8b-4d3f-d659-d06db24b43fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 15.3 s, sys: 2.09 s, total: 17.4 s\n",
            "Wall time: 20min 19s\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
        "              'min_samples_leaf': list(np.linspace(5, 25, 10, dtype=int)),\n",
        "              'max_depth': list(np.linspace(1, 30, 6, dtype=int))\n",
        "              }\n",
        "\n",
        "gs_rf = GridSearchCV(\n",
        "    estimator = ensemble.RandomForestClassifier(random_state= 42),\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time gs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_gs_rf = gs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edzwav_LARg9",
        "outputId": "eea330a6-e5c1-403c-ba7f-e2a1411d7861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'max_depth': 18, 'min_samples_leaf': 5, 'n_estimators': 170}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjqMX-a1srO8",
        "outputId": "b84316d7-6c3d-43e8-aff6-6994b1bde177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на GridResearchCV для случайного леса равен 0.80\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на GridResearchCV для случайного леса равен {:.2f}'.format(f1_gs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTQLKOPA80Gy"
      },
      "source": [
        "##### **Построение модели с помощью RandomizedSearchCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ-55UX5F9aZ"
      },
      "source": [
        "\n",
        "*на основе логистической регресии:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ktb2x0suWk",
        "outputId": "9c3463d1-fda7-4770-e423-b689af027b72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "60 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.78676988 0.78039406 0.784572   0.78559647 0.77977812 0.7720333\n",
            " 0.77964432 0.78764576 0.77738608 0.77916669        nan 0.78437918\n",
            "        nan 0.78910458 0.77930432 0.78794459 0.75772746 0.78110073\n",
            " 0.77446388        nan 0.75772746 0.77994879 0.78586785 0.78160775\n",
            " 0.78162978 0.77793982 0.78548284        nan 0.78525485        nan\n",
            " 0.78776434        nan 0.78118038 0.78015342 0.77979571 0.78795813\n",
            " 0.78315714        nan 0.78940981        nan        nan 0.78767421\n",
            " 0.77907345 0.7763647  0.7821919  0.78860478 0.78006037        nan\n",
            "        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4.12 s, sys: 696 ms, total: 4.82 s\n",
            "Wall time: 7min 31s\n"
          ]
        }
      ],
      "source": [
        "param_random = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C': list(np.linspace(0.01, 1, 10, dtype=float))}, # уровень силы регурялизации\n",
        "\n",
        "    # так как разные алгоритмы поддерживают разные типы регуляризации, то создадим еще 1 набор параметров\n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
        "]\n",
        "\n",
        "rs_logReg = RandomizedSearchCV(\n",
        "    estimator= linear_model.LogisticRegression(random_state=42, max_iter=50),\n",
        "    param_random=param_random,\n",
        "    cv = 5,\n",
        "    n_iter = 50,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time rs_logReg.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_logReg = rs_logReg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDH21jB845z",
        "outputId": "efbdfec3-7dba-445a-f9a5-05a15a9e6ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.45}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo2MWmhBAr3e",
        "outputId": "80b2edb4-c82b-41ad-b29c-a5437339b143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на RandomizedSrearchCV для логистической регресии равен 0.78\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на RandomizedSrearchCV для логистической регресии равен {:.2f}'.format(f1_rs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpOAAqFqGLAe"
      },
      "source": [
        "*на основе случайного леса:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g__0RRm_At5O",
        "outputId": "e49becdd-810c-47d1-ea74-aba9d9541d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4.76 s, sys: 486 ms, total: 5.24 s\n",
            "Wall time: 4min 9s\n"
          ]
        }
      ],
      "source": [
        "param_random = {\n",
        "    'min_samples_leaf' : list(np.linspace(5, 25, 10, dtype=int)),\n",
        "    'max_depth' : list(np.linspace(1, 30, 6, dtype = int)),\n",
        "    'n_estimators' : list(range(80, 200, 30))\n",
        "}\n",
        "\n",
        "rs_rf = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
        "    param_random=param_random,\n",
        "    cv = 5,\n",
        "    n_iter = 50,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time rs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_rf = rs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RsiaxP5CpsU",
        "outputId": "f40375d8-38ad-446e-a15f-7208113c8281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 18}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhuf3omSCqH-",
        "outputId": "c3475d26-6618-4465-a5d6-4dd890d9ee26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на RandomizedSrearchCV для случайного леса равен 0.80\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на RandomizedSrearchCV для случайного леса равен {:.2f}'.format(f1_rs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rDbxusMCvaj"
      },
      "source": [
        "##### **Построение модели с помощью HyperOpt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_GHeZmmGWlZ"
      },
      "source": [
        "\n",
        "*на основе логистической регресии:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9drh-NjQE-8",
        "outputId": "c8edd8b2-f577-4dbe-8213-24e339ad1e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 50/50 [15:29<00:00, 18.59s/trial, best loss: -0.7928648789728487]\n",
            "Лучшие гиперпараметры: {'C': 0.020162206477661048, 'penalty': 1, 'solver': 1}\n"
          ]
        }
      ],
      "source": [
        "# Создаем пространство гиперпараметров\n",
        "space = {\n",
        "    'penalty': hp.choice(label='penalty', options=['l1', 'l2']),  # тип регуляризации\n",
        "    'solver': hp.choice(label='solver', options=['liblinear', 'saga']),  # алгоритм оптимизации\n",
        "    'C': hp.loguniform(label='C', low=-2 * np.log(10), high=2 * np.log(10))  # уровень силы регуляризации\n",
        "}\n",
        "\n",
        "random_state = 42 # зафиксируем random_state\n",
        "\n",
        "def hyperopt_lr(params, cv=5, X=None, y=None, random_state=random_state):\n",
        "\n",
        "    # Инициализация модели с переданными параметрами\n",
        "    model = linear_model.LogisticRegression(\n",
        "        penalty=params['penalty'],\n",
        "        solver=params['solver'],\n",
        "        C=params['C'],\n",
        "        random_state=random_state,\n",
        "        max_iter=50\n",
        "    )\n",
        "\n",
        "    # Применим кросс-валидацию\n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "\n",
        "    # Для минимизации F1-метрики ставим знак минус\n",
        "    return -score\n",
        "\n",
        "# Логирование результатов\n",
        "trials = Trials()\n",
        "\n",
        "# Запуск оптимизации с Hyperopt\n",
        "best = fmin(fn=lambda params: hyperopt_lr(params, X=X_train, y=y_train),\n",
        "            space=space,  # пространство гиперпараметров\n",
        "            algo=tpe.suggest,  # алгоритм оптимизации\n",
        "            max_evals=50,  # количество итераций\n",
        "            trials=trials,  # логирование результатов\n",
        "            rstate=np.random.default_rng(random_state))  # генератор случайных чисел\n",
        "\n",
        "print(f'Лучшие гиперпараметры: {best}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Находим наилучшую best_loss (отрицательный F1-score для лучших гиперпараметров) и преобразуем обратно в F1-score\n",
        "best_loss = min(trials.losses())\n",
        "best_f1_score = -best_loss  # так как мы минимизируем отрицательный F1\n",
        "\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(best))\n",
        "print(f\"F1-score на HyperOpt для логистической регресии равен : {best_f1_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NsPRVibUE7w",
        "outputId": "580230e5-4a45-45ad-fea8-f0e14dd4665b"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров: {'C': 0.020162206477661048, 'penalty': 1, 'solver': 1}\n",
            "F1-score на HyperOpt для логистической регресии равен : 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKzL1CaBGkdB"
      },
      "source": [
        "*на основе случайного леса:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "YHamKh9P10OG"
      },
      "outputs": [],
      "source": [
        "# Создаем пространство гиперпараметров\n",
        "space={'n_estimators': hp.quniform('n_estimators', 80, 200, 1),\n",
        "       'max_depth' : hp.quniform('max_depth', 1, 30, 1),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 5, 25, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "44l1HJv210RO"
      },
      "outputs": [],
      "source": [
        "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
        "\n",
        "    params = {'n_estimators': int(params['n_estimators']),\n",
        "              'max_depth': int(params['max_depth']),\n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "    }\n",
        "    # используем эту комбинацию для построения модели\n",
        "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
        "\n",
        "    # обучаем модель\n",
        "    model.fit(X, y)\n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "\n",
        "    # Для минимизации F1-метрики ставим знак минус\n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R_ZFoZalFg2",
        "outputId": "2afab750-30cd-4fff-c3be-5b3b67966e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.11 µs\n",
            "100%|██████████| 50/50 [08:07<00:00,  9.74s/trial, best loss: -0.8126347227817426]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 27.0, 'min_samples_leaf': 6.0, 'n_estimators': 198.0}\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "best = fmin(hyperopt_rf, # наша функция\n",
        "          space = space, # пространство гиперпараметров\n",
        "          algo = tpe.suggest, # алгоритм оптимизации\n",
        "          max_evals = 50, # максимальное количество итераций\n",
        "          trials = trials, # логирование результатов\n",
        "          rstate=np.random.default_rng(random_state)  # фиксируем для повторяемости результата\n",
        ")\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Находим наилучшую best_loss (отрицательный F1-score для лучших гиперпараметров) и преобразуем обратно в F1-score\n",
        "best_loss = min(trials.losses())\n",
        "best_f1_score = -best_loss  # так как мы минимизируем отрицательный F1\n",
        "\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(best))\n",
        "print(f\"F1-score на HyperOpt для случайного леса равен : {best_f1_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijbhOGcXepUx",
        "outputId": "1627d46f-f764-424c-e573-0da521b96ce7"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров: {'max_depth': 27.0, 'min_samples_leaf': 6.0, 'n_estimators': 198.0}\n",
            "F1-score на HyperOpt для случайного леса равен : 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0_r_K2hK4-9"
      },
      "source": [
        "##### **Построение модели с помощью Optuna**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1_XVz3GcAh"
      },
      "source": [
        "\n",
        "*на основе логистической регресии:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pnHb1k5J_hs1"
      },
      "outputs": [],
      "source": [
        "def optuna_lr(trial):\n",
        "    penalty = trial.suggest_categorical(name='penalty', choices= ['l1', 'l2']) # тип регуляризации\n",
        "    solver = trial.suggest_categorical(name = 'solver', choices= ['liblinear', 'saga']) # алгоритм оптимизации\n",
        "    C = trial.suggest_float(name='C', low=0.01, high=1, step = 0.1) # уровень силы регурялизации\n",
        "\n",
        "    random_state = 42 # зафиксируем random_state\n",
        "\n",
        "    model = linear_model.LogisticRegression(\n",
        "        penalty = penalty,\n",
        "        solver = solver,\n",
        "        C = C,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK3LkvMb_hwG",
        "outputId": "fd24d813-7c9d-484d-e5b6-2b576bdee82d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-10 12:09:34,371] A new study created in memory with name: LogisticRegression\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:11:13,527] Trial 0 finished with value: 0.7850653891519912 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.6100000000000001}. Best is trial 0 with value: 0.7850653891519912.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:11:15,689] Trial 1 finished with value: 0.7809977986548946 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 0 with value: 0.7850653891519912.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:12:28,102] Trial 2 finished with value: 0.778228428701617 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.51}. Best is trial 0 with value: 0.7850653891519912.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:12:30,726] Trial 3 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:12:38,549] Trial 4 finished with value: 0.7744496937620166 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.91}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:33,789] Trial 5 finished with value: 0.778228428701617 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.51}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:36,593] Trial 6 finished with value: 0.7855928486362146 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.7100000000000001}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:40,131] Trial 7 finished with value: 0.7761275867915696 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.81}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:43,962] Trial 8 finished with value: 0.7771767488479819 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.7100000000000001}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:47,346] Trial 9 finished with value: 0.7824159224810836 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.81}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:13:58,465] Trial 10 finished with value: 0.757727458318251 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.01}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:00,995] Trial 11 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:02,967] Trial 12 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:04,928] Trial 13 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:06,150] Trial 14 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:08,116] Trial 15 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:10,798] Trial 16 finished with value: 0.7871037546890695 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.41000000000000003}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:14:12,770] Trial 17 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:42,459] Trial 18 finished with value: 0.7876686666304757 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.41000000000000003}. Best is trial 3 with value: 0.7890248612255107.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:44,656] Trial 19 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:45,716] Trial 20 finished with value: 0.757727458318251 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.01}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:47,227] Trial 21 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:48,753] Trial 22 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:50,148] Trial 23 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:52,482] Trial 24 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:15:56,203] Trial 25 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:16:58,474] Trial 26 finished with value: 0.7848050656291596 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.11}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:17:00,776] Trial 27 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:17:02,156] Trial 28 finished with value: 0.757727458318251 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.01}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:20,751] Trial 29 finished with value: 0.783572756566549 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.51}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:23,296] Trial 30 finished with value: 0.7871037546890695 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.41000000000000003}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:25,559] Trial 31 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:27,753] Trial 32 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:29,637] Trial 33 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:31,578] Trial 34 finished with value: 0.7809977986548946 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:18:33,549] Trial 35 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:19:42,569] Trial 36 finished with value: 0.7787206199228413 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.41000000000000003}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:19:44,092] Trial 37 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:19:46,360] Trial 38 finished with value: 0.7808510233734516 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.51}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:19:48,290] Trial 39 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:42,113] Trial 40 finished with value: 0.7786062450191485 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.6100000000000001}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:43,668] Trial 41 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:45,214] Trial 42 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:47,185] Trial 43 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:48,166] Trial 44 finished with value: 0.757727458318251 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.01}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:49,709] Trial 45 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:50,966] Trial 46 finished with value: 0.7865688010718683 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.11}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:53,676] Trial 47 finished with value: 0.7890248612255107 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:56,003] Trial 48 finished with value: 0.7897328628801042 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}. Best is trial 19 with value: 0.7897328628801042.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:693: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n",
            "[I 2025-01-10 12:20:58,759] Trial 49 finished with value: 0.7771572701655801 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.31000000000000005}. Best is trial 19 with value: 0.7897328628801042.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 3s, sys: 2.96 s, total: 2min 6s\n",
            "Wall time: 11min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='LogisticRegression', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_lr, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем наилучшие значения гиперпараметров и F1-score\n",
        "best_params_opt_lr = study.best_params\n",
        "best_f1_score_opt_lr = study.best_value\n",
        "\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(best_params_opt_lr))\n",
        "print(f\"F1-score на Optuna для логистической регрессии равен: {best_f1_score_opt_lr:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxGhSCPrh6LT",
        "outputId": "76047723-b4df-42eb-9434-beac267aac05"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.21000000000000002}\n",
            "F1-score на Optuna для логистической регрессии равен: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPrgnRKGqVO"
      },
      "source": [
        "*на основе случайного леса:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PtSS31XcNwoz"
      },
      "outputs": [],
      "source": [
        "def optuna_rf(trial):\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
        "\n",
        "    random_state = 42 # зафиксируем random_state\n",
        "\n",
        "    model = ensemble.RandomForestClassifier(\n",
        "        n_estimators = n_estimators,\n",
        "        max_depth = max_depth,\n",
        "        min_samples_leaf = min_samples_leaf,\n",
        "        random_state = random_state\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'f1', n_jobs= -1).mean()\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eu7HpfsN0sU",
        "outputId": "f9d5da6b-588a-4667-9cdd-3796eb60b7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-10 12:24:18,088] A new study created in memory with name: RandomForestClassification\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:24:25,412] Trial 0 finished with value: 0.782274892836979 and parameters: {'n_estimators': 144, 'max_depth': 9, 'min_samples_leaf': 24}. Best is trial 0 with value: 0.782274892836979.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:24:37,069] Trial 1 finished with value: 0.8056507660480895 and parameters: {'n_estimators': 137, 'max_depth': 19, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:24:47,375] Trial 2 finished with value: 0.7935403155379858 and parameters: {'n_estimators': 187, 'max_depth': 13, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:24:55,843] Trial 3 finished with value: 0.7976328792288319 and parameters: {'n_estimators': 114, 'max_depth': 28, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:08,402] Trial 4 finished with value: 0.8027499752767673 and parameters: {'n_estimators': 179, 'max_depth': 26, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:15,476] Trial 5 finished with value: 0.7868317754600394 and parameters: {'n_estimators': 147, 'max_depth': 7, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:20,588] Trial 6 finished with value: 0.7743094821206217 and parameters: {'n_estimators': 99, 'max_depth': 6, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:28,391] Trial 7 finished with value: 0.7794367654853052 and parameters: {'n_estimators': 87, 'max_depth': 16, 'min_samples_leaf': 25}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:35,582] Trial 8 finished with value: 0.7909409813000293 and parameters: {'n_estimators': 134, 'max_depth': 9, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:41,914] Trial 9 finished with value: 0.7651329178323325 and parameters: {'n_estimators': 152, 'max_depth': 5, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.8056507660480895.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:25:54,910] Trial 10 finished with value: 0.8077645082869653 and parameters: {'n_estimators': 169, 'max_depth': 21, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.8077645082869653.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:26:09,823] Trial 11 finished with value: 0.8110655908686365 and parameters: {'n_estimators': 178, 'max_depth': 21, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:26:24,649] Trial 12 finished with value: 0.8074936338176067 and parameters: {'n_estimators': 170, 'max_depth': 23, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:26:37,008] Trial 13 finished with value: 0.7914558755242433 and parameters: {'n_estimators': 200, 'max_depth': 21, 'min_samples_leaf': 20}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:26:39,888] Trial 14 finished with value: 0.7195449782031601 and parameters: {'n_estimators': 166, 'max_depth': 1, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:26:54,839] Trial 15 finished with value: 0.8051575388833481 and parameters: {'n_estimators': 199, 'max_depth': 24, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:27:07,083] Trial 16 finished with value: 0.806896933787594 and parameters: {'n_estimators': 163, 'max_depth': 17, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:27:16,575] Trial 17 finished with value: 0.7915303081122157 and parameters: {'n_estimators': 185, 'max_depth': 12, 'min_samples_leaf': 18}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:27:27,774] Trial 18 finished with value: 0.8056144381573865 and parameters: {'n_estimators': 121, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:27:40,066] Trial 19 finished with value: 0.8084901333020836 and parameters: {'n_estimators': 159, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:27:49,672] Trial 20 finished with value: 0.8086583754525056 and parameters: {'n_estimators': 155, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:01,845] Trial 21 finished with value: 0.8084134966379427 and parameters: {'n_estimators': 157, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:15,218] Trial 22 finished with value: 0.8008586485452721 and parameters: {'n_estimators': 179, 'max_depth': 24, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:26,220] Trial 23 finished with value: 0.8067928637608667 and parameters: {'n_estimators': 155, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:34,577] Trial 24 finished with value: 0.7959182574111303 and parameters: {'n_estimators': 130, 'max_depth': 18, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:46,551] Trial 25 finished with value: 0.7915803141540761 and parameters: {'n_estimators': 176, 'max_depth': 21, 'min_samples_leaf': 17}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:28:59,769] Trial 26 finished with value: 0.8067484274943594 and parameters: {'n_estimators': 189, 'max_depth': 15, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:29:14,816] Trial 27 finished with value: 0.8040642732031309 and parameters: {'n_estimators': 162, 'max_depth': 22, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:29:22,836] Trial 28 finished with value: 0.7932420829246686 and parameters: {'n_estimators': 124, 'max_depth': 27, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:29:33,109] Trial 29 finished with value: 0.8040529302844439 and parameters: {'n_estimators': 140, 'max_depth': 12, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:29:40,592] Trial 30 finished with value: 0.7929647425008719 and parameters: {'n_estimators': 147, 'max_depth': 25, 'min_samples_leaf': 21}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:29:52,695] Trial 31 finished with value: 0.8084134966379427 and parameters: {'n_estimators': 157, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:03,649] Trial 32 finished with value: 0.807925143184422 and parameters: {'n_estimators': 158, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:14,027] Trial 33 finished with value: 0.8100353160487938 and parameters: {'n_estimators': 145, 'max_depth': 17, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:26,580] Trial 34 finished with value: 0.8100353160487938 and parameters: {'n_estimators': 145, 'max_depth': 17, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8110655908686365.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:38,899] Trial 35 finished with value: 0.8114148162283513 and parameters: {'n_estimators': 145, 'max_depth': 16, 'min_samples_leaf': 6}. Best is trial 35 with value: 0.8114148162283513.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:45,923] Trial 36 finished with value: 0.8079132146854338 and parameters: {'n_estimators': 111, 'max_depth': 11, 'min_samples_leaf': 6}. Best is trial 35 with value: 0.8114148162283513.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:30:58,397] Trial 37 finished with value: 0.8087049984304656 and parameters: {'n_estimators': 144, 'max_depth': 15, 'min_samples_leaf': 6}. Best is trial 35 with value: 0.8114148162283513.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:08,653] Trial 38 finished with value: 0.8082117601729802 and parameters: {'n_estimators': 134, 'max_depth': 17, 'min_samples_leaf': 6}. Best is trial 35 with value: 0.8114148162283513.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:16,131] Trial 39 finished with value: 0.7990742700802596 and parameters: {'n_estimators': 112, 'max_depth': 10, 'min_samples_leaf': 7}. Best is trial 35 with value: 0.8114148162283513.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:23,786] Trial 40 finished with value: 0.8121234983747133 and parameters: {'n_estimators': 101, 'max_depth': 14, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:31,869] Trial 41 finished with value: 0.810637786729101 and parameters: {'n_estimators': 97, 'max_depth': 14, 'min_samples_leaf': 6}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:37,235] Trial 42 finished with value: 0.8025007663585203 and parameters: {'n_estimators': 80, 'max_depth': 13, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:46,740] Trial 43 finished with value: 0.8118269451736422 and parameters: {'n_estimators': 102, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:31:52,175] Trial 44 finished with value: 0.7936048777208595 and parameters: {'n_estimators': 99, 'max_depth': 8, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:32:01,517] Trial 45 finished with value: 0.8017659423023129 and parameters: {'n_estimators': 100, 'max_depth': 14, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:32:08,042] Trial 46 finished with value: 0.8087600179473886 and parameters: {'n_estimators': 94, 'max_depth': 13, 'min_samples_leaf': 5}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:32:15,288] Trial 47 finished with value: 0.7944005421604223 and parameters: {'n_estimators': 88, 'max_depth': 10, 'min_samples_leaf': 8}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:32:21,055] Trial 48 finished with value: 0.7819758031102085 and parameters: {'n_estimators': 107, 'max_depth': 16, 'min_samples_leaf': 22}. Best is trial 40 with value: 0.8121234983747133.\n",
            "<ipython-input-43-3c134b65791b>:2: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
            "<ipython-input-43-3c134b65791b>:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
            "<ipython-input-43-3c134b65791b>:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
            "[I 2025-01-10 12:32:25,097] Trial 49 finished with value: 0.7634683785322608 and parameters: {'n_estimators': 105, 'max_depth': 5, 'min_samples_leaf': 7}. Best is trial 40 with value: 0.8121234983747133.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 49s, sys: 2.12 s, total: 1min 52s\n",
            "Wall time: 8min 7s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='RandomForestClassification', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_rf, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем наилучшие значения гиперпараметров и F1-score\n",
        "\n",
        "best_params_opt_rf = study.best_params\n",
        "best_f1_score_opt_rf = study.best_value\n",
        "\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(best_params_opt_rf))\n",
        "print(f\"F1-score на Optuna для логистической регрессии равен: {best_f1_score_opt_rf:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqL_OtcNIpg9",
        "outputId": "d748b96e-7e21-4684-e4ef-71a415a22ae0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наилучшие значения гиперпараметров: {'n_estimators': 101, 'max_depth': 14, 'min_samples_leaf': 6}\n",
            "F1-score на Optuna для логистической регрессии равен: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PLYIJOHI6oBT",
        "outputId": "fb38449f-e174-4581-ec0f-8ed0bf150fc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"fbe8c000-fc00-4aba-9f75-df900f5d291f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fbe8c000-fc00-4aba-9f75-df900f5d291f\")) {                    Plotly.newPlot(                        \"fbe8c000-fc00-4aba-9f75-df900f5d291f\",                        [{\"mode\":\"markers\",\"name\":\"F1-score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.782274892836979,0.8056507660480895,0.7935403155379858,0.7976328792288319,0.8027499752767673,0.7868317754600394,0.7743094821206217,0.7794367654853052,0.7909409813000293,0.7651329178323325,0.8077645082869653,0.8110655908686365,0.8074936338176067,0.7914558755242433,0.7195449782031601,0.8051575388833481,0.806896933787594,0.7915303081122157,0.8056144381573865,0.8084901333020836,0.8086583754525056,0.8084134966379427,0.8008586485452721,0.8067928637608667,0.7959182574111303,0.7915803141540761,0.8067484274943594,0.8040642732031309,0.7932420829246686,0.8040529302844439,0.7929647425008719,0.8084134966379427,0.807925143184422,0.8100353160487938,0.8100353160487938,0.8114148162283513,0.8079132146854338,0.8087049984304656,0.8082117601729802,0.7990742700802596,0.8121234983747133,0.810637786729101,0.8025007663585203,0.8118269451736422,0.7936048777208595,0.8017659423023129,0.8087600179473886,0.7944005421604223,0.7819758031102085,0.7634683785322608],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.782274892836979,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8056507660480895,0.8077645082869653,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8110655908686365,0.8114148162283513,0.8114148162283513,0.8114148162283513,0.8114148162283513,0.8114148162283513,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133,0.8121234983747133],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"F1-score\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fbe8c000-fc00-4aba-9f75-df900f5d291f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study, target_name=\"F1-score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. Оценка метрики F1-score и сравнение результатов**"
      ],
      "metadata": {
        "id": "7i7kRceKQIeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате выполненных расчетов получили следующие данные:<br>\n",
        "1. Для базовой модели: <br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.78.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.81.<br>\n",
        "2. Построение модели с помощью GridSearchCV:<br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.79.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.80.<br>\n",
        "3. Построение модели с помощью RandomizedSearchCV:<br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.78.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.80.<br>\n",
        "4. Построение модели с помощью HyperOpt:<br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.79.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.81.<br>\n",
        "5. Построение модели с помощью Optuna:<br>\n",
        "F1-метрика (F1-score) c использованием логистической регрессия равна: 0.79.<br>\n",
        "F1-метрика (F1-score) c использованием алгоритма случайнго леса равна: 0.81.<br>"
      ],
      "metadata": {
        "id": "KpvLWbcwQgJd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}